{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import operator\n",
    "import string\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "PATH =\"/home/rick/UH-Spring-2019/Project/codescoop-models/Libraries_io_data/repositories-1.2.0-2018-03-12.csv\"\n",
    "dataRepo = pd.read_csv(PATH, nrows = 300000, index_col=False)\n",
    "dataRepo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build functions that we need for processing descriptions and data\n",
    "\n",
    "# counting word frequencies\n",
    "def words_freq(s):\n",
    "    d={}\n",
    "    for i in s.split():\n",
    "\n",
    "        if i in d:\n",
    "            d[i] +=1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d\n",
    "\n",
    "# converting variables to dummies\n",
    "def getDummies (data, feature):\n",
    "    dummies = pd.get_dummies(data[feature])\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "    data = data.drop([feature],axis=1)\n",
    "    return data\n",
    "\n",
    "# get_neighbors returns k nearest neighbours for an instance\n",
    "def get_neighbors(k, instance, data, labels):\n",
    "    distances = []\n",
    "    index = labels[labels == instance].index[0]\n",
    "    inst = data.iloc[index]\n",
    "    for i in range(len(data)):\n",
    "        dist = np.linalg.norm(np.array(inst) - np.array(data.iloc[i]))\n",
    "        distances.append((dist, i))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = distances[1:k+1]\n",
    "    indexes = [x[1] for x in neighbors]\n",
    "    print(indexes)\n",
    "    # loc OR iloc?\n",
    "    return labels.iloc[indexes]\n",
    "\n",
    "def get_neighbors_improved(instance, data, labels):\n",
    "    index = labels[labels == instance].index[0]\n",
    "    inst = np.array(data[index]).reshape(1, -1)\n",
    "    distances, indices = nbrs.kneighbors(inst)\n",
    "    print(indices)\n",
    "    # loc OR iloc?\n",
    "    return labels.iloc[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findig keywords to use in knn\n",
    "dataRepo.Keywords.fillna(0, inplace=True)\n",
    "dataRepo.Description.fillna(0, inplace=True)\n",
    "dataRepo = dataRepo[dataRepo.Description != 0]\n",
    "\n",
    "\n",
    "descriptions = list(dataRepo.Description)\n",
    "\n",
    "joinedDescriptions = \" \".join(descriptions)\n",
    "joinedDescriptions = joinedDescriptions.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(joinedDescriptions)\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "filtered_sentence = \" \".join(filtered_sentence)\n",
    "\n",
    "word_freq = words_freq(filtered_sentence)\n",
    "sortedList = sorted(word_freq.items(), key = operator.itemgetter(1), reverse=True)\n",
    "sortedDict = dict(sortedList)\n",
    "topWords = list(sortedDict.keys())[:500]\n",
    "print(topWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize numeric variables, should we weigh these somehow?\n",
    "numeric_vars = ['Stars Count', 'Contributors Count', 'Forks Count']\n",
    "knn_num = dataRepo[numeric_vars]\n",
    "knn_num = knn_num.apply(lambda col: ((col-np.mean(col))/np.std(col)), axis=0)\n",
    "\n",
    "# add dummies for language and keywords\n",
    "knn_data = dataRepo[['Language', 'Description']]\n",
    "knn_data = getDummies(knn_data, 'Language')\n",
    "\n",
    "for word in topWords:\n",
    "    newcol = np.zeros(len(knn_data))\n",
    "    i = 0;\n",
    "    for row in knn_data['Description']:\n",
    "        if(word in row):\n",
    "            newcol[i] = 1\n",
    "        i += 1\n",
    "    knn_data[word] = newcol\n",
    "\n",
    "# join numeric variables to knn data\n",
    "knn_data[numeric_vars] = knn_num\n",
    "knn_data = knn_data.drop(['Description'],axis=1)\n",
    "knn_data.head()\n",
    "\n",
    "names = dataRepo['Name with Owner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO\n",
    "\n",
    "# calculate k nearest neighbours for a project\n",
    "nbrs = get_neighbors(5, \"immense/knockout-pickatime\", knn_data, names)\n",
    "print(nbrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a NN model, this takes a while but then retrieving info is very fast\n",
    "\n",
    "knn_data = np.array(knn_data)\n",
    "nbrs = NearestNeighbors(n_neighbors=6, algorithm='auto').fit(knn_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrsTEST = get_neighbors_improved(\"immense/knockout-pickatime\", knn_data, names)\n",
    "print(nbrsTEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
